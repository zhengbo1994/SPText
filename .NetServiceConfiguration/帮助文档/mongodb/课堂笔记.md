#  课堂笔记

~~~shell
当内存使用值超过了maxmemory配置时，redis可以使用以下策略进行数据淘汰。

●noeviction：（默认策略）当达到内存限制并且客户端尝试执行可能导致使用更多内存的命令时返回错。 key=项目名称：业务：XXX  肯定数据不会丢失--服务不可用
●volatile-lru：删除设置了过期时间的key而且最近最少使用key（LRU算法淘汰）。
●allkeys-lru：删除所有比较最近最少使用的key（LRU算法淘汰）。
## 把最近使用频率低的删除掉，有可能删除我们使用周期长的数据，因为可能最近很少使用，不代表我们不使用

●volatile-lfu：删除设置了过期时间的key而且使用频率最低key（LFU算法淘汰）。
●allkeys-lfu：删除所有使用频率最低的key（LFU算法淘汰）。
key 使用了多少次---使用使用的次数越少，则表示可能会被删除；还是有可能把业务数据删除了


●volatile-random：设置了过期时间的key使用随机淘汰。
●allkeys-random：所有key使用随机淘汰。
●volatile-ttl：设置了过期时间的key根据过期时间淘汰，越早过期越早淘汰。
马上快要过期的数据淘汰。。。


~~~

高频面试题：

~~~
1.redis 用了好久，半年多，发现内存占用很大。。然后它把一些key删除---
内存没有释放--

碎片管理： 重启redis , 如果内存比较小，可以直接修改配置文件，代表我们可用内存的百分比剩下多少的时候，帮忙我们去碎片整理。如果碎片整理过于频繁会降级我们redis的性能。
~~~

~~~shell
缓存雪崩：同一时间有大量的key过期了，导致我们请求数据的时候，在redis里面查询不到，这个时候直接取查询我们关系型数据库---如果并发量比较大导致我们服务不可用。
解决办法：在设置关键时间的时候，不要设置同样的时间，写一个过期因子。1-1000s
比如大量的key都是50min过期，50min+随机秒数；

缓存穿透：代表数据不在mysql数据库里面也不在redis里面，首先查询redis，然后redis没有数据，查询mysql数据库。
1.造成mysql压力
2.这个数据本身在mysql里面
可能原因，是恶意破坏。。
解决方案：
1.如果第一次操作，如果在redis没有，在mysql也没有，我就把这个恶意key存在在redis，values设置成null;第二次查询的时候，直接返回null ..不建议这么做，如果真的是恶意话。。这种情况占用大量的内存
2.布隆过滤器
每次操作key的时候，把这个key写入到我们布隆过滤器里面去，
然后查询的时候，先查询布隆过滤器，如果布隆过滤器有，则继续查询redis和mysql。如果说布隆过滤器没有，则返回就行。。。占用少量的内存，存放了大量的key，而且能很快速的判断我们key存在不存在。 误判（这个数据没有，但是给的结果是有，这个概率比较小，而且就算是误判了，也不会造成我们业务问题）。前提就是我们操作业务的时候，首先吧key要写入到布隆过滤器里面。第一次课已经讲解了它的原理，已经.net代码怎么去调用。

随便写个key --
缓存击穿：代表这个key在数据库，不在redis中，可能过期吗
解决方案：直接让这个key不要设置过期时间的就行。。
缓存预热： 我们业务代码：先查询redis，如果redis没有，查询mysql，然后把数据在存放到redis中，为了给下次查询提供。
1.项目才开始启动，然后防止一开始并发量大直接查询mysql数据库，所以在启动之前，自己写个程序，把这些数据存储到redis。
2.数据可能会过期：写一个程序，时不时把数据预热，往redis写一次。。（mongodb预热用的比较多）

~~~

## Mongodb

~~~shell
Mongo：带表大。。。中小型企业的10亿+算是最大的数据量。。。BP --- HBASE---明天老师扩展说些
是关系型数据库和非关系型数据库一种；
~~~

~~~shell
docker run -d --name mongo1 -p 27017:27017 mongo
~~~

1. 我就想要严格的操作mongo，可以，自己去创建一个map:。net代码写的类要和map里面对字段类型要一致，如果多了一个字段，或者少一个字段，或者类型不对，则不会写入成功。。

2. 和mysql区别，mongodb它不能做两和集合连查。。可以通过数据冗余的办法，实现连查的效果。如果一个文档（json）16M会报错。。如果超过，把数据存在多个文档，然后根据一个关联字段去关联就行。。比较特殊--一般的业务完全够用。。。

   

   NOSQL:特性速度写入速度快 ，刷盘机制。。写数据的时候，先不要把数据之间存放在硬盘，随机写，耗性能，异步刷盘，先把数据写入到内存，然后根据刷盘机制把数据存放到硬盘。。有可能造成数据丢失。。

   需要把mysql的数据迁移mongodb里面去，但是需要提高性能。。

   前段学员，mongodb ,压测。。通过mysql和mogndo。

   1.如果for循环查询，mogndo性能要比mysql要快

   2.批量操作。发现mongodb要比mysql要慢？

   解决方案。先把刷盘时间改大，把缓冲区空间改大。。

   mongodb事务：

   4版本之后，支持了事务，支持事务之前，必须要搭建集群，如果不是集群，则也不会支持事务。

   ~~~shell
   use test2
   db.createCollection("userinfo")
   s=db.getMongo().startSession()
   s.startTransaction()
   s.getDatabase("test").userinfo.insert({name:"a"})
   > [Error] Transaction numbers are only allowed on a replica set member or mongos
   at line 5, column 1
   > 时间: 0.011s
   表示mongodb单机版不能支持我们事务。。
   
   ~~~

   集群方式：

   1.副本集。读写分离，主节点负责写，从节点负责读，通过数据冗余

   2.分片。多个主节点，多个从节点，一个主节点负责一部分数据。。

   # 答疑

   ## 副本集
   
   ~~~shell
   简单主从，通过数据备份，当主节点宕的时候，从节点会替代主节点工作
   1.实现读写分离，提高读能力
   2.实现了高可用
   
   ps:如果只是一主一从。只能做备份，不能实现高可用。
   一个主多个从是可以实现高可用。。。
   当主节点宕机，其中一个从节点会替代主节点工作，然后当主节点回来之后，变成从节点。
   ~~~
   
   ## 索引
   
   ~~~shell
   db.c1.createIndex({age:1},{background:true,expireAfterSeconds:150,name:"ix_age",unique:true});
   db.c1.find({age:18}).explain('executionStats'); 
   db.c1.getIndexes()
   ~~~
   
   

如果有兴趣，看一下上期录屏，提供了12个节点，三个宿主机上面实现的分片；

mongodb 插入文档，id字段名称_id，如果插入的时候，不赋值，则系统会默认分配一个guid不重复的值，_id是主键。但是如果想要赋值，也可以，直接给_id赋值，但是要保证我们值不能重复，如果重复，则这个文档不会被写入进去。

ps:如果数据库做了分片，不建议大家去自己给_id赋值，为了系统能好的负载均衡（散列）。

## 扩展

~~~shell
pd级别的数据--- <=10亿
当下互联网，no sql，redis,hbase ;
大数据---本质--让数据又价值--钱--- 
数据量大，而且不一样。。每一年有一个流行色---

让数据又意义-- 收集数据---各式各样的数据
              清洗数据--格式化处理数据
              分析统计--- 
              
  数据已经有了，PB级别的---  hbase 等等 
  
  hbase:列数据库：k:v
  1。对数据随机读写，数据增删改查
  2.高并发操作-- 比如，一秒能对PB级别的数据，进行上千次不等操作
  3.读和写都是简单的操作。。
  
  松散存储--nosql---列族 （一个列族里面可以存放多个字段）
  创建数据库的时候，只要把列族创建好就行，至于你这列族里面几个字段，随便你。。
  
  高效查询只能通过rowkey：1001 这个，要么直接=rowkey,要么给rowkey范围
  --非常重要，设计者rowkey --包含了使用了它的60%== 思想思维--
  
  hbase,分片是根据rowkey来分配，
  尽量让我们的rowkey分配均匀，还有松散， 可以利用多个节点，
  业务，有时候，需要查询的时候，可能需要尽量让查询的这个数据在一个节点上面。。
  
  具体的业务具体分析：思想
  12312341234---》 2021-20-20： 
  
  12312341234%30--- 查询怎么办--- 统计，把这个手机号码一年的统计出来
  
  均衡
  12312341234  202101 
  30个不同的节点上面去
  0
  29
  
  
  
  
            


~~~



