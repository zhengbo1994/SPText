# 笔记

~~~shell
Producer:
 生产者：生产数据，就是我们客户端代码，写数据的
Consumer：
 消费者:负责处理kafka服务里面消息
Consumer Group/Consumers：
 消费者组：就是kafka独特处理轮询还是广播。
 轮询：消费者每一个处理一条，轮排
 广播：一条信息，多个消费者同时处理，比如，日志，写了文本日志，还写数据库日志
Broker：就是kafka服务，一个Broker可以创建多个topic
Topic：就是一个写入broker主题，一个kafka集群里面可以有多个Topic,为了区分业务和模块使用
Partition：就是把一个topic的信息分成几个区，利用多个节点，把多个分区，放在不同节点上面，实现负载均衡，kafka内部实现的。。 
Replica：副本，就是防止主节点宕机，然后数据丢失了，保证高可用。。
Offset：偏移量，就是消息的主键，生产者负责写数据的时候，写进去然后偏移量，消费者消费数据，知道数据消费到什么地方，不要重复消费==

~~~

分区数量，最好和节点数据一致。。。 但是副本，还是看具体情况，也不定每一个节点都有一个，压力大。。根据自己情况来选择。。

面试题： kafka的数据写入是有顺序的吗？？？？

1. 如果默认一个分区，则是有顺序

2. 如果是多个分区，则不能保证数据的顺序，

   


面试第二题目

ISR: 同步的副本集合，维护当前还在存活办事的副本，解决防止当我们一个副本出现问题时候，不能正常的返回ack..

面试第三题：

通过什么来维护ISR: 是根据心跳，还是我们备份数据量。。。条数，时间

条数，leader和副本数据只差，超过这个配置差，则就认为副本节点不行，然后从isr移除，当数据备份跟的上来，然后又纳入到我们ISR集合

时间：多久的时间没有进行心跳。。。 超过配置时间，则认为不行，移除，当心跳跟的上，在进入集合

随机应变： kafka是个高吞吐的消息队列， 发送数据的时候，有批量发送的功能，每次发数据的可以发送大量的数据，这个是可配的。。 所以如果根据条数，则副本节点，会经常性的从isr移除和增加进气。。 因为这种考虑，kafka的开发者，选择使用了第二种，根据时间来判断。。 还有个问题，数据不一致。。消费端看到的数据不一致怎么办？？后面我们在来看，怎么解决。。

ack=0:性能最高，但是当写入到leader之后，返回ack，还没有落盘，则宕机，然数据丢失。日志收集系统，iot设备上传信息，都选择它，性能最高，可能会丢。。

ack=1.性能中等，然后数据写入leader落盘，然后返回ack，当落盘返回ack之后，leader挂了，则新的leader还没有备份数据，则数据丢失，只能通过人工参与找到丢的数据。。比较鸡肋。。食之无味弃之可惜。。

ack=-1,性能最差，当leader和所有的副本节点都备份完成之后，在返回ack。肯定肯定不会有数据丢失，但是有了其他的问题。。当数据都备份了，然后此时此刻leader没有返回ack，然后宕机，则新的副本替代它，然后客户端生产者因为没有收到ack，所以补偿重试，再次发送信息，最后，数据重复。。可以结合配置，开启幂等性，发送的数据的时候，服务端会验证我们信息的唯一性，如果之前发送过，就不在接受，然后只会保留一条相同的信息。。 

差的原因：1.数据备份慢，所有的副本都要备份完才返回，

​                2.如果开启幂等性，则服务端接受数据的时候，要验证数据的唯一性。。

没有开启幂等性，相当于，就是id，开启幂等性，就是主键id...

如果真的是要用kafka，用第一个最多，iot平台。云平台，

所有的日志都是kafka,发布版本通知===都是kafka

设备--- 上行是kafka，下行是rabbitmq

上行：设备的信息，心跳，状态，申请， 真的丢失。。设备没有收到通知，会自动触发重试。

下行：一个平台对设备，尽量不要丢，需要设备返回ack，然后云平台重试。。 用rabbitmq

抛砖引玉===具体看得看需求，看领导的心情===  



答疑环节。。。。。。 

1、消费数据是先消费Leader中数据还是副本中数据

Leader

2、副本和leader就是两份一模一样的数据，消费后，两份数据都清空嘛，什么时候清空

保留7天，kafka可以配置。。默认7天，消息积压有处理。。 

3、副本和leader不一致岂不是有些没有备份了？如果ISR移出了副本，冗余就失效了吗

就是一个问题，消费端，100 --消费偏移量-- 明天会讲到，有个机制会解决这个问题。。

老师看下环境 中的 三个 分区的 leader 和follower的分布吧

4个节点，一个topic，4个分区。。。 应该？个副本，能保证只要剩下都能正常进行业务不丢失。。。 肯定是4个，但是慎重，不能太多，

１．在数据完整性方面，RabbitMq会比Kafka好吗？

必然：RabbitMq要好，和开发语言还有网络有关系，人写的代码肯定多多有问题。win系统，

２．在同一个Topic下，可以根据Key来区分消息类型吗？

不能，消费端只关心topic和偏移量--其余不关心。。

３．消息的Value长度有限制吗，很大的Json会有影响吗（如几M的数据）？

提供性能，底层是二进制。。可以使用protbuf节省内存，数据量越小，性能越高。。可以aop。。 

．消费者一般用哪种方式好，控制台，WinForm还是Web的？

用workservice（net5）。。 

没有跨平台之前用windows 服务，

集群才有分区概念？单机没有？

都有，但是单机搞分区无意义。。返回降低性能，不要忘了初衷。。。

kfk为什么高吞吐

明天会讲到。。。

3个节点，3个分区，怎么交叉备份的



这不是rabbitmq的负载均衡么-- 最终处理任务还是一个，，，不管上层怎么负载，最后还是一个苦干。。 

加入了消息队列组件 是不是所有的业务请求都走消息队列 还是特定的写入场景才需要队列呢

比如：微服务里面事件企业总线。。mq..  

解耦，削峰，必选mq..

Kalfa数据落盘，leader 和 follower 可以共用吗？ 还是必须，各备份各的

各是各的。。。

![image-20210521222255209](%E7%AC%94%E8%AE%B0.assets/image-20210521222255209.png)

批量提交消费的偏移量，但是提交了，数据批量写的时候宕机，那不就凉凉了吗，，，想办法。。。 

要不然就，先数据库，然后批量返回偏移量，

可以在swarm中搭建集群吗。。。

k8s..swarm redis- mongdodb,kafka,es 集群。。 可以吗，

但是不算是原生对接k8s.. 

比如redis 6个节点，3主3从。。k8s,其中一个节点挂了，保证在来开启一个。。 

数据怎么办？？ k8s共享。。。 

扩容。。。缩容。。。

不是完美的对接。。。

tidb--new sql。完美对接云原生。。 扩容，缩容，，，保证节点挂了，在启动一个，原生支持。。。

tidb--内部实现，当有一个新节点，内部把数据平均一下，缩容之后，也是自己平均一下，都是自己发现自己干==

像中间件--基本都是单独搞的。。。

 



幂等性：开启服务端验证。。。消息的msgid，客户端id===>+单个分区 。。 

多个分区：消息的msgid，客户端id，分区id (key)=== 必须要事务的模式。。



顺序读写：业务场景

关系型数据库不适合-- 数据有增删改，不能浪费硬盘，写，有空位置，就可以存。。读--不能顺序读，客户有条件

一些nosql--也是进行增删改--为什么它们能顺序读写--- 



1.批量发送
1.1.生产者发送数据批量
1.2消费端，消费的时候，一次性获取多条消费

2.顺序读写
mongodb，日志刷盘--顺序读写
kafka---数据落盘直接是顺序读写-- 数据只有新增，没有删除，没有修改--删的时候，
到了7天之后，统一删除---
es--数据日志追加--顺序读写
redis---aof日志追加--顺序读写
hbase--落盘--顺序读写（增删改）
hive--日志追加--顺序读写  
mysql--主从复制-- 顺序读写

不同的场景使用不同的思维和技术---

hadoop

hdsf -- mapreduce --yarm

![image-20210522204826883](%E7%AC%94%E8%AE%B0.assets/image-20210522204826883.png)



顺序读写高效--多个电脑去处理数据写入-- 流式处理



消费端：组和组之间是广播模式，组内是根据分区数量

一定一定要注意，如果要消费者做负载均衡--则分区数量最好和同一个组的消费者数量一致

topic的数量=broker的数量

broker数量=分区数量

分区数量=一个组内的消费者数量





答疑：



请问一下老师：
1，做 新闻类 网站，首页用 动态页，刷新闻的时候，用redis好 还是 mongodb好 或是 es好？

nginx+动静分离+lua-- 

nginx,redis-内存

2，做 首页 单用户新闻推荐时候，比较常用做法 是不是 es（关键字检索） + reids（新闻标题+用户ID）？然后定时推荐。

队列，TOPIC，分区 不能由生产者创建吧？不能源码创建？必须每次从管理页面手动创建？



老师 kafka中 topic主要是充当什么角色 主要是干那些事的  有点模糊 可以讲解一下吗

目标：干嘛-- 根据业务，模块，项目 

卡夫卡 是不是不能像rabbitmq消费了就提交，删数据。只能通过自身 日志压缩 删除。

保留7天-- 可配置



兔子mq为什么有时会阻塞

刚刚那个消费者跳转的能继续演示吗[呲牙]。。。。

通过UI可以把分区数量动态增加或减少吗。

实际情况，先扩容broker，然后在增加分区

多少吞吐量以上用kafka，就是多少之下用rabbitmq就可以了（大约）

kafka--重，服务器--集群+分片 

kafka和rabbitmq的使用场景区别

结合实际业务，然后根据优点和缺点来选型

昨天答疑说了一些，看看

kafka重--- 

rabbitmq轻--丢数据的概率比kafka小，集群--镜像不能负载均衡--》最终处理的还是一个



怎么定时定量的消费？比如发送邮件的时候，积累了500个，10秒内只发送100个，下一个10秒在发100，生产者自己管，，自己搞

![image-20210522224056427](%E7%AC%94%E8%AE%B0.assets/image-20210522224056427.png)

高级消费：就是超过时间没有提交偏移量，则会给下一个消费端来消费这个

消息，，依次类推，什么时候消费完了，就处理完了这个消息

